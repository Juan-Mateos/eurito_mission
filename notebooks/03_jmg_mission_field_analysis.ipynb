{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission field analysis\n",
    "\n",
    "We start the analisys of the enriched GTR dataset (see `01` and `02` notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = pd.read_csv('../data/processed/22_1_2019_projects_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings query / Clio query?\n",
    "\n",
    "To keep things simple, we will train a w2v model, identify synonyms for a set of seed terms and query the data for those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load lda_pipeline.py\n",
    "from gensim import corpora, models\n",
    "from string import punctuation\n",
    "from string import digits\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "#Characters to drop\n",
    "drop_characters = re.sub('-','',punctuation)+digits\n",
    "\n",
    "#Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('English')\n",
    "\n",
    "#Stem functions\n",
    "from nltk.stem import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def flatten_list(a_list):\n",
    "    return([x for el in a_list for x in el])\n",
    "\n",
    "\n",
    "def clean_tokenise(string,drop_characters=drop_characters,stopwords=stop):\n",
    "    '''\n",
    "    Takes a string and cleans (makes lowercase and removes stopwords)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "\n",
    "    #Lowercase\n",
    "    str_low = string.lower()\n",
    "    \n",
    "    \n",
    "    #Remove symbols and numbers\n",
    "    str_letters = re.sub('[{drop}]'.format(drop=drop_characters),'',str_low)\n",
    "    \n",
    "    \n",
    "    #Remove stopwords\n",
    "    clean = [x for x in str_letters.split(' ') if (x not in stop) & (x!='')]\n",
    "    \n",
    "    return(clean)\n",
    "\n",
    "\n",
    "class CleanTokenize():\n",
    "    '''\n",
    "    This class takes a list of strings and returns a tokenised, clean list of token lists ready\n",
    "    to be processed with the LdaPipeline\n",
    "    \n",
    "    It has a clean method to remove symbols and stopwords\n",
    "    \n",
    "    It has a bigram method to detect collocated words\n",
    "    \n",
    "    It has a stem method to stem words\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,corpus):\n",
    "        '''\n",
    "        Takes a corpus (list where each element is a string)\n",
    "        '''\n",
    "        \n",
    "        #Store\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def clean(self,drop=drop_characters,stopwords=stop):\n",
    "        '''\n",
    "        Removes strings and stopwords, \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        cleaned = [clean_tokenise(doc,drop_characters=drop,stopwords=stop) for doc in self.corpus]\n",
    "        \n",
    "        self.tokenised = cleaned\n",
    "        return(self)\n",
    "    \n",
    "    def stem(self):\n",
    "        '''\n",
    "        Optional: stems words\n",
    "        \n",
    "        '''\n",
    "        #Stems each word in each tokenised sentence\n",
    "        stemmed = [[stemmer.stem(word) for word in sentence] for sentence in self.tokenised]\n",
    "    \n",
    "        self.tokenised = stemmed\n",
    "        return(self)\n",
    "        \n",
    "    \n",
    "    def bigram(self,threshold=10):\n",
    "        '''\n",
    "        Optional Create bigrams.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Colocation detector trained on the data\n",
    "        phrases = models.Phrases(self.tokenised,threshold=threshold)\n",
    "        \n",
    "        bigram = models.phrases.Phraser(phrases)\n",
    "        \n",
    "        self.tokenised = bigram[self.tokenised]\n",
    "        \n",
    "        return(self)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class LdaPipeline():\n",
    "    '''\n",
    "    This class processes lists of keywords.\n",
    "    How does it work?\n",
    "    -It is initialised with a list where every element is a collection of keywords\n",
    "    -It has a method to filter keywords removing those that appear less than a set number of times\n",
    "    \n",
    "    -It has a method to process the filtered df into an object that gensim can work with\n",
    "    -It has a method to train the LDA model with the right parameters\n",
    "    -It has a method to predict the topics in a corpus\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,corpus):\n",
    "        '''\n",
    "        Takes the list of terms\n",
    "        '''\n",
    "        \n",
    "        #Store the corpus\n",
    "        self.tokenised = corpus\n",
    "        \n",
    "    def filter(self,minimum=5):\n",
    "        '''\n",
    "        Removes keywords that appear less than 5 times.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Load\n",
    "        tokenised = self.tokenised\n",
    "        \n",
    "        #Count tokens\n",
    "        token_counts = pd.Series([x for el in tokenised for x in el]).value_counts()\n",
    "        \n",
    "        #Tokens to keep\n",
    "        keep = token_counts.index[token_counts>minimum]\n",
    "        \n",
    "        #Filter\n",
    "        tokenised_filtered = [[x for x in el if x in keep] for el in tokenised]\n",
    "        \n",
    "        #Store\n",
    "        self.tokenised = tokenised_filtered\n",
    "        self.empty_groups = np.sum([len(x)==0 for x in tokenised_filtered])\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    def clean(self):\n",
    "        '''\n",
    "        Remove symbols and numbers\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def process(self):\n",
    "        '''\n",
    "        This creates the bag of words we use in the gensim analysis\n",
    "        \n",
    "        '''\n",
    "        #Load the list of keywords\n",
    "        tokenised = self.tokenised\n",
    "        \n",
    "        #Create the dictionary\n",
    "        dictionary = corpora.Dictionary(tokenised)\n",
    "        \n",
    "        #Create the Bag of words. This converts keywords into ids\n",
    "        corpus = [dictionary.doc2bow(x) for x in tokenised]\n",
    "        \n",
    "        self.corpus = corpus\n",
    "        self.dictionary = dictionary\n",
    "        return(self)\n",
    "        \n",
    "    def tfidf(self):\n",
    "        '''\n",
    "        This is optional: We extract the term-frequency inverse document frequency of the words in\n",
    "        the corpus. The idea is to identify those keywords that are more salient in a document by normalising over\n",
    "        their frequency in the whole corpus\n",
    "        \n",
    "        '''\n",
    "        #Load the corpus\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        #Fit a TFIDF model on the data\n",
    "        tfidf = models.TfidfModel(corpus)\n",
    "        \n",
    "        #Transform the corpus and save it\n",
    "        self.corpus = tfidf[corpus]\n",
    "        \n",
    "        return(self)\n",
    "    \n",
    "    def fit_lda(self,num_topics=20,passes=5,iterations=75,random_state=1803):\n",
    "        '''\n",
    "        \n",
    "        This fits the LDA model taking a set of keyword arguments.\n",
    "        #Number of passes, iterations and random state for reproducibility. We will have to consider\n",
    "        reproducibility eventually.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #Load the corpus\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        #Train the LDA model with the parameters we supplied\n",
    "        lda = models.LdaModel(corpus,id2word=self.dictionary,\n",
    "                              num_topics=num_topics,passes=passes,iterations=iterations,random_state=random_state)\n",
    "        \n",
    "        #Save the outputs\n",
    "        self.lda_model = lda\n",
    "        self.lda_topics = lda.show_topics(num_topics=num_topics)\n",
    "        \n",
    "\n",
    "        return(self)\n",
    "    \n",
    "    def predict_topics(self):\n",
    "        '''\n",
    "        This predicts the topic mix for every observation in the corpus\n",
    "        \n",
    "        '''\n",
    "        #Load the attributes we will be working with\n",
    "        lda = self.lda_model\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        #Now we create a df\n",
    "        predicted = lda[corpus]\n",
    "        \n",
    "        #Convert this into a dataframe\n",
    "        predicted_df = pd.concat([pd.DataFrame({x[0]:x[1] for x in topics},\n",
    "                                              index=[num]) for num,topics in enumerate(predicted)]).fillna(0)\n",
    "        \n",
    "        self.predicted_df = predicted_df\n",
    "        \n",
    "        return(self)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sentence corpus\n",
    "sentence_corpus = flatten_list([x.split('. ') for x in projects['abstract']])\n",
    "\n",
    "\n",
    "#Tokenize etc using the classes above\n",
    "sentence_tokenised = CleanTokenize(sentence_corpus).clean().bigram()\n",
    "\n",
    "#Also tokenise by documents so we can query them later\n",
    "corpus_tokenised = CleanTokenize(projects['abstract']).clean().bigram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training W2V\n",
    "w2v = Word2Vec(sentence_tokenised.tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/{today_str}_word_embeddings.p','wb') as outfile:\n",
    "    pickle.dump(w2v,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_chaser(seed_list,model,similarity,occurrences=1):\n",
    "    '''\n",
    "    Takes a seed term and expands it with synonyms (above a certain similarity threshold)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #All synonyms of the terms in the seed_list above a certain threshold\n",
    "    set_ws = flatten_list([[term[0] for term in model.most_similar(seed) if term[1]>similarity] for seed in seed_list])\n",
    "    \n",
    "    #return(set_ws)\n",
    "    \n",
    "    #This is the list of unique occurrences (what we want to return at the end)\n",
    "    set_ws_list = list(set(set_ws))\n",
    "    \n",
    "    #For each term, if it appears multiple times, we expand\n",
    "    for w in set_ws:\n",
    "        if set_ws.count(w)>occurrences:\n",
    "            \n",
    "            #As before\n",
    "            extra_words = [term[0] for term in model.most_similar(w) if term[1]>similarity]\n",
    "            \n",
    "            set_ws_list + extra_words\n",
    "            \n",
    "    #return(list(set(set_ws_list)))\n",
    "    return(set_ws_list)\n",
    "    \n",
    "\n",
    "    \n",
    "def querier(corpus,keywords):\n",
    "    '''\n",
    "    Loops over a tokenised corpus and returns the number of hits (number of times that any of the terms appears in the document)\n",
    "    \n",
    "    '''\n",
    "    #Intersection of tokens\n",
    "    out = [len(set(keywords) & set(document)) for document in corpus]\n",
    "    \n",
    "    return(out)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI and Chronic diseases (crude keyword search-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "ai_expanded = synonym_chaser(seed_list=['machine_learning','artificial_intelligence','deep_learning','ai','machine_vision'],model=w2v,similarity=0.8)\n",
    "chronic_expanded = synonym_chaser(seed_list=['chronic_disease','chronic'],model=w2v,similarity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['has_ai'],projects['has_chronic'] = [querier(corpus_tokenised.tokenised,keys) for keys in [ai_expanded,chronic_expanded]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>has_chronic</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_ai</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>95.769475</td>\n",
       "      <td>97.681704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>4.230525</td>\n",
       "      <td>2.318296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "has_chronic      False      True \n",
       "has_ai                           \n",
       "False        95.769475  97.681704\n",
       "True          4.230525   2.318296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*pd.crosstab(projects['has_ai']>0,projects['has_chronic']>0,normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>status</th>\n",
       "      <th>grant_category</th>\n",
       "      <th>funder</th>\n",
       "      <th>amount</th>\n",
       "      <th>biological_sciences</th>\n",
       "      <th>physics</th>\n",
       "      <th>...</th>\n",
       "      <th>arts_humanities</th>\n",
       "      <th>prods</th>\n",
       "      <th>ip</th>\n",
       "      <th>tech</th>\n",
       "      <th>spin</th>\n",
       "      <th>pubs</th>\n",
       "      <th>has_ai</th>\n",
       "      <th>has_chronic</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_inclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>01B6A723-34E3-4F13-9318-5257D1FC1D54</td>\n",
       "      <td>Non-invasive assessment and management of coro...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>The main aim is to improve and test software c...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Fellowship</td>\n",
       "      <td>MRC</td>\n",
       "      <td>284559.0</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>1.280349e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.989821e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0248EE56-D9BA-4D29-A438-BA2BD05A3168</td>\n",
       "      <td>Micromechanical measurements in living embryos</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>The embryo is a complex system wherein local t...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>BBSRC</td>\n",
       "      <td>585065.0</td>\n",
       "      <td>0.469256</td>\n",
       "      <td>2.409735e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.811508e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0283F735-409F-49A2-9DEB-2DCF4E8884D5</td>\n",
       "      <td>VIRTUAL REALITY ASSESSMENT AND REHABILITATION ...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>The proposed PhD project will use innovative, ...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Studentship</td>\n",
       "      <td>EPSRC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>5.355883e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.159070e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>0A62A025-8483-4E00-B724-7286B6DF772E</td>\n",
       "      <td>A Universal PAN Architecture for Monitoring Mu...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>People living with chronic medical conditions ...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>EPSRC</td>\n",
       "      <td>179286.0</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>3.143689e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.501907e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>0C7B23FD-07CE-420B-B9FE-7C0860B83199</td>\n",
       "      <td>Learning MRI and histology image mappings for ...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>This project aims to exploit recent advances i...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>EPSRC</td>\n",
       "      <td>774254.0</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>1.584342e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>8.204334e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     index  \\\n",
       "409   01B6A723-34E3-4F13-9318-5257D1FC1D54   \n",
       "545   0248EE56-D9BA-4D29-A438-BA2BD05A3168   \n",
       "619   0283F735-409F-49A2-9DEB-2DCF4E8884D5   \n",
       "2586  0A62A025-8483-4E00-B724-7286B6DF772E   \n",
       "3097  0C7B23FD-07CE-420B-B9FE-7C0860B83199   \n",
       "\n",
       "                                                  title    year  \\\n",
       "409   Non-invasive assessment and management of coro...  2018.0   \n",
       "545      Micromechanical measurements in living embryos  2013.0   \n",
       "619   VIRTUAL REALITY ASSESSMENT AND REHABILITATION ...  2017.0   \n",
       "2586  A Universal PAN Architecture for Monitoring Mu...  2008.0   \n",
       "3097  Learning MRI and histology image mappings for ...  2017.0   \n",
       "\n",
       "                                               abstract  status  \\\n",
       "409   The main aim is to improve and test software c...  Active   \n",
       "545   The embryo is a complex system wherein local t...  Closed   \n",
       "619   The proposed PhD project will use innovative, ...  Active   \n",
       "2586  People living with chronic medical conditions ...  Closed   \n",
       "3097  This project aims to exploit recent advances i...  Active   \n",
       "\n",
       "      grant_category funder    amount  biological_sciences       physics  \\\n",
       "409       Fellowship    MRC  284559.0             0.000366  1.280349e-07   \n",
       "545   Research Grant  BBSRC  585065.0             0.469256  2.409735e-09   \n",
       "619      Studentship  EPSRC       0.0             0.000403  5.355883e-06   \n",
       "2586  Research Grant  EPSRC  179286.0             0.000147  3.143689e-04   \n",
       "3097  Research Grant  EPSRC  774254.0             0.000120  1.584342e-05   \n",
       "\n",
       "          ...        arts_humanities  prods   ip  tech  spin  pubs  has_ai  \\\n",
       "409       ...           1.989821e-08    0.0  0.0   0.0   0.0   0.0       1   \n",
       "545       ...           3.811508e-07    0.0  0.0   2.0   0.0   4.0       1   \n",
       "619       ...           9.159070e-04    0.0  0.0   0.0   0.0   0.0       1   \n",
       "2586      ...           3.501907e-02    0.0  0.0   0.0   0.0   0.0       1   \n",
       "3097      ...           8.204334e-06    0.0  0.0   0.0   0.0   0.0       2   \n",
       "\n",
       "      has_chronic  has_age  has_inclusion  \n",
       "409             1        0              0  \n",
       "545             1        0              0  \n",
       "619             1        0              0  \n",
       "2586            1        0              0  \n",
       "3097            1        0              0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.loc[(projects['has_ai']>0) & (projects['has_chronic']>0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ageing and inclusion/inequality (crude keyword search-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "age_expanded = synonym_chaser(seed_list=['ageing','aging'],model=w2v,similarity=0.8)\n",
    "inclusion_expanded = synonym_chaser(seed_list=['inclusion','inclusiveness','inclusive','inequality'],model=w2v,similarity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects['has_age'],projects['has_inclusion'] = [querier(corpus_tokenised.tokenised,keys) for keys in [age_expanded,inclusion_expanded]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>has_inclusion</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>68628</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1964</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "has_inclusion  False  True \n",
       "has_age                    \n",
       "False          68628   1727\n",
       "True            1964     37"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(projects['has_age']>0,projects['has_inclusion']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>status</th>\n",
       "      <th>grant_category</th>\n",
       "      <th>funder</th>\n",
       "      <th>amount</th>\n",
       "      <th>biological_sciences</th>\n",
       "      <th>physics</th>\n",
       "      <th>...</th>\n",
       "      <th>arts_humanities</th>\n",
       "      <th>prods</th>\n",
       "      <th>ip</th>\n",
       "      <th>tech</th>\n",
       "      <th>spin</th>\n",
       "      <th>pubs</th>\n",
       "      <th>has_ai</th>\n",
       "      <th>has_chronic</th>\n",
       "      <th>has_age</th>\n",
       "      <th>has_inclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>098AFC90-05C9-4F53-A584-F780EA2BD004</td>\n",
       "      <td>MECHANISM OF INFLAMMATION IN ENVIRONMENTAL ENT...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Malnutrition is the greatest barrier to health...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Fellowship</td>\n",
       "      <td>MRC</td>\n",
       "      <td>815863.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.192120e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>0AA6BCA6-50DD-4767-87B2-AFE0D7399233</td>\n",
       "      <td>Enabling Ongoingness: Content Creation &amp;amp; C...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>The 'oldest old' are the fastest growing age g...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>EPSRC</td>\n",
       "      <td>885437.0</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.483308e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10048</th>\n",
       "      <td>27E22B78-1328-4874-B4A1-A2BBD48F00D7</td>\n",
       "      <td>Causes of heterogeneity in ageing - the Whiteh...</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>When the Whitehall II study started in 1985 it...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>MRC</td>\n",
       "      <td>2099998.0</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>4.291643e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>2835D915-D062-4B01-89BC-140637C6A54D</td>\n",
       "      <td>How do neighbourhood deprivation and neighbour...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>How do neighbourhood deprivation and neighbour...</td>\n",
       "      <td>Active</td>\n",
       "      <td>Studentship</td>\n",
       "      <td>ESRC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>4.205033e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>28649AB9-D8A5-4017-905A-7A4147D98915</td>\n",
       "      <td>Family Demography and Health in Low- and Middl...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Intergenerational relations involve the exchan...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Research Grant</td>\n",
       "      <td>ESRC</td>\n",
       "      <td>17070.0</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1.276702e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      index  \\\n",
       "2370   098AFC90-05C9-4F53-A584-F780EA2BD004   \n",
       "2656   0AA6BCA6-50DD-4767-87B2-AFE0D7399233   \n",
       "10048  27E22B78-1328-4874-B4A1-A2BBD48F00D7   \n",
       "10142  2835D915-D062-4B01-89BC-140637C6A54D   \n",
       "10178  28649AB9-D8A5-4017-905A-7A4147D98915   \n",
       "\n",
       "                                                   title    year  \\\n",
       "2370   MECHANISM OF INFLAMMATION IN ENVIRONMENTAL ENT...  2018.0   \n",
       "2656   Enabling Ongoingness: Content Creation &amp; C...  2017.0   \n",
       "10048  Causes of heterogeneity in ageing - the Whiteh...  2010.0   \n",
       "10142  How do neighbourhood deprivation and neighbour...  2017.0   \n",
       "10178  Family Demography and Health in Low- and Middl...  2013.0   \n",
       "\n",
       "                                                abstract  status  \\\n",
       "2370   Malnutrition is the greatest barrier to health...  Active   \n",
       "2656   The 'oldest old' are the fastest growing age g...  Active   \n",
       "10048  When the Whitehall II study started in 1985 it...  Closed   \n",
       "10142  How do neighbourhood deprivation and neighbour...  Active   \n",
       "10178  Intergenerational relations involve the exchan...  Closed   \n",
       "\n",
       "       grant_category funder     amount  biological_sciences       physics  \\\n",
       "2370       Fellowship    MRC   815863.0             0.000027  1.192120e-08   \n",
       "2656   Research Grant  EPSRC   885437.0             0.000029  1.483308e-09   \n",
       "10048  Research Grant    MRC  2099998.0             0.000966  4.291643e-08   \n",
       "10142     Studentship   ESRC        0.0             0.001661  4.205033e-06   \n",
       "10178  Research Grant   ESRC    17070.0             0.000142  1.276702e-07   \n",
       "\n",
       "           ...        arts_humanities  prods   ip  tech  spin   pubs  has_ai  \\\n",
       "2370       ...               0.000001    0.0  0.0   0.0   0.0    0.0       0   \n",
       "2656       ...               0.415132    0.0  0.0   0.0   0.0    0.0       0   \n",
       "10048      ...               0.000847    0.0  0.0   0.0   0.0  944.0       0   \n",
       "10142      ...               0.001017    0.0  0.0   0.0   0.0    0.0       0   \n",
       "10178      ...               0.002074    0.0  0.0   0.0   0.0   14.0       0   \n",
       "\n",
       "       has_chronic  has_age  has_inclusion  \n",
       "2370             1        1              1  \n",
       "2656             0        1              1  \n",
       "10048            1        3              1  \n",
       "10142            0        1              1  \n",
       "10178            0        1              1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.loc[(projects['has_age']>0) & (projects['has_inclusion']>0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the beginning of an approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "* Integrate with TRL analysis\n",
    "* Integrate with SDG analysis\n",
    "* Generate metrics\n",
    "* Check social media discussion around papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
